{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP approach to data extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st method "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the content and write it in a txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "import docx2txt\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def move_files(input_directory, output_directory):\n",
    "    for file in os.listdir(input_directory):\n",
    "        if file.endswith(\".txt\"):\n",
    "            shutil.move(os.path.join(input_directory, file), output_directory)\n",
    "            \n",
    "# This first part of the code converts all the .docx files to .txt files\n",
    "directory = glob.glob(r\"C:\\Users\\garsonj\\Desktop\\NLP\\new_sample_docx\\*.docx\")\n",
    "old_path = r\"C:\\Users\\garsonj\\Desktop\\NLP\\new_sample_docx\"\n",
    "\n",
    "for file_name in directory:\n",
    "    with open(file_name, 'rb') as infile:\n",
    "        doc = docx2txt.process(infile)\n",
    "        outfile_path = file_name[:-5] + '.txt'  # Output file path\n",
    "        with open(outfile_path, 'w', encoding='utf-8') as outfile:\n",
    "            outfile.write(doc)\n",
    "\n",
    "# This second part of the code moves all the .txt files to a new folder\n",
    "txts = [f for f in os.listdir(old_path) if f.lower().endswith('.txt')]\n",
    "\n",
    "new_path = r'C:\\Users\\garsonj\\Desktop\\NAO_sample\\sample_non_cleaned_txt'\n",
    "\n",
    "move_files(r\"C:\\Users\\garsonj\\Desktop\\NLP\\new_sample_docx\", r\"C:\\Users\\garsonj\\Desktop\\NLP\")\n",
    "\n",
    "print(\"=========\")\n",
    "print(\"All done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd method"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open windows and convert directly inside windows the docx to txt format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "from win32com import client as wc\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def convert_to_txt(file):\n",
    "    w = wc.Dispatch('Word.Application')\n",
    "    doc = w.Documents.Open(file)\n",
    "    doc.SaveAs2(file[:-5] + '.txt', 2)  # Save as a plain text file with .txt extension\n",
    "\n",
    "    doc.Close()  # Close the Word document\n",
    "    w.Quit()  # Close the Word application\n",
    "\n",
    "def move_files(input_directory, output_directory):\n",
    "    for file in os.listdir(input_directory):\n",
    "        if file.endswith(\".txt\"):\n",
    "            shutil.move(os.path.join(input_directory, file), output_directory)\n",
    "    \n",
    "directory = glob.glob(r\"C:\\Users\\garsonj\\Desktop\\NLP\\new_sample_docx\\*.docx\")\n",
    "output_directory = r\"C:\\Users\\garsonj\\Desktop\\NLP\"\n",
    "\n",
    "for file in directory:\n",
    "    convert_to_txt(file)\n",
    "\n",
    "move_files(r\"C:\\Users\\garsonj\\Desktop\\NLP\\new_sample_docx\", r\"C:\\Users\\garsonj\\Desktop\\NLP\")\n",
    "\n",
    "print(\"=========\")\n",
    "print(\"All done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first function is just removing stopwords in text. The results are excellent since we reduce size by around 25% without loss of meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "\n",
    "def clean_text(file_path):\n",
    "    stop_words = set(stopwords.words('french'))\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    cleaned_text = ' '.join(filtered_words)\n",
    "\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(cleaned_text)\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "\n",
    "directory = r\".\\sample_txt_not_cleaned\"\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    if file.endswith(\".txt\"):\n",
    "        file_path = os.path.join(directory, file)\n",
    "        clean_text(file_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second function include a keyword selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.\\\\sample_txt_not_cleaned\\\\T03323012438-39256238500014.docx.txt\\\\T06222007558-57578017600039.docx.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 98\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[39mif\u001b[39;00m file\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.txt\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     97\u001b[0m     file_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(file_path, file)\n\u001b[1;32m---> 98\u001b[0m     clean_text(file_path)\n",
      "Cell \u001b[1;32mIn[7], line 81\u001b[0m, in \u001b[0;36mclean_text\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclean_text\u001b[39m(file_path):\n\u001b[0;32m     79\u001b[0m     stop_words \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(stopwords\u001b[39m.\u001b[39mwords(\u001b[39m'\u001b[39m\u001b[39mfrench\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m---> 81\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(file_path, \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m     82\u001b[0m         text \u001b[39m=\u001b[39m file\u001b[39m.\u001b[39mread()\n\u001b[0;32m     84\u001b[0m     words \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39msplit()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.\\\\sample_txt_not_cleaned\\\\T03323012438-39256238500014.docx.txt\\\\T06222007558-57578017600039.docx.txt'"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "from docx import Document\n",
    "from docx.enum.text import WD_COLOR\n",
    "from docxcompose.composer import Composer\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import shutil\n",
    "from win32com import client as wc\n",
    "\n",
    "# Define a function to move files from one folder to another\n",
    "def move_files(input_directory, output_directory):\n",
    "    for file in os.listdir(input_directory):\n",
    "        if file.endswith(\".docx\"):\n",
    "            shutil.move(os.path.join(input_directory, file), output_directory)  \n",
    "\n",
    "# Define a function to extract paragraph of a docx file\n",
    "\n",
    "# Define a function to extract the file name without extension\n",
    "def extract_file_name(file):\n",
    "    file_name = os.path.basename(file)\n",
    "    file_name_without_extension = os.path.splitext(file_name)[0]\n",
    "    return file_name_without_extension\n",
    "\n",
    "# Define a function to process all *.docx files in a folder\n",
    "def process_docx_files(folder_path):\n",
    "    # Import keywords from the Excel file and turn them into a list\n",
    "    df = pd.read_excel('keywords.xlsx')\n",
    "    list_of_words = df['keywords'].tolist()\n",
    "    # Set up regex\n",
    "    patterns = [r'\\b' + word + r'\\b' for word in list_of_words]\n",
    "    re_highlight = re.compile('(' + '|'.join(p for p in patterns) + ')+', re.IGNORECASE)\n",
    "    docx_files = glob.glob(folder_path + '\\\\*.docx')\n",
    "    for file in docx_files:\n",
    "        doc = Document(file)\n",
    "        title = extract_file_name(file)  # Extract the file name without extension\n",
    "        modified_doc = Document()  # Create a new document to store modified paragraphs\n",
    "        modified_doc.add_heading(title, level=1)  # Add the title as Header 1 to the modified document\n",
    "        for para in doc.paragraphs:\n",
    "            text = para.text\n",
    "            if len(re_highlight.findall(text)) > 0:\n",
    "                matches = re_highlight.finditer(text)\n",
    "                p3 = 0\n",
    "                highlighted_para = modified_doc.add_paragraph()  # Add a new paragraph to the modified document\n",
    "                for match in matches:\n",
    "                    p1 = p3\n",
    "                    p2, p3 = match.span()\n",
    "                    highlighted_para.add_run(text[p1:p2])\n",
    "                    run = highlighted_para.add_run(text[p2:p3])\n",
    "                    run.font.highlight_color = WD_COLOR.YELLOW\n",
    "                    highlighted_para.add_run(text[p3:])\n",
    "        if modified_doc.paragraphs:  # Only save the modified document if it contains highlighted paragraphs\n",
    "            modified_doc.save(file)\n",
    "\n",
    "# Provide the folder path where the algorithm will iterate over all *.docx files\n",
    "folder_path = r\".\\new_sample_docx\"\n",
    "process_docx_files(folder_path)\n",
    "\n",
    "# Now convert them to .txt files\n",
    "\n",
    "def convert_to_txt(file):\n",
    "    w = wc.Dispatch('Word.Application')\n",
    "    doc = w.Documents.Open(file)\n",
    "    doc.SaveAs(file[:-5] + '.txt', 2)  # Save as a plain text file with .txt extension\n",
    "\n",
    "    doc.Close()  # Close the Word document\n",
    "    w.Quit()  # Close the Word application\n",
    "\n",
    "directory = glob.glob(r\"C:\\Users\\garsonj\\Desktop\\NLP\\new_sample_docx\\*.docx\")\n",
    "\n",
    "for file in directory:\n",
    "    convert_to_txt(file)\n",
    "\n",
    "move_files(r\"C:\\Users\\garsonj\\Desktop\\NLP\\new_sample_docx\", r\"C:\\Users\\garsonj\\Desktop\\NLP\")\n",
    "\n",
    "# Define a function to remove stopwords from a text file\n",
    "def clean_text(file_path):\n",
    "    stop_words = set(stopwords.words('french'))\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    cleaned_text = ' '.join(filtered_words)\n",
    "\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(cleaned_text)\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "file_path = r\".\\sample_txt_not_cleaned\"\n",
    "\n",
    "for file in os.listdir(file_path):\n",
    "    if file.endswith(\".txt\"):\n",
    "        file_path = os.path.join(file_path, file)\n",
    "        clean_text(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "from docx import Document\n",
    "from docx.enum.text import WD_COLOR\n",
    "from docxcompose.composer import Composer\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import shutil\n",
    "from win32com import client as wc\n",
    "\n",
    "# Define a function to move files from one folder to another\n",
    "def move_files(input_directory, output_directory):\n",
    "    for file in os.listdir(input_directory):\n",
    "        if file.endswith(\".docx.txt\"):  # Modified the file extension check\n",
    "            shutil.move(os.path.join(input_directory, file), output_directory)  \n",
    "\n",
    "# Define a function to extract the file name without extension\n",
    "def extract_file_name(file):\n",
    "    file_name = os.path.basename(file)\n",
    "    file_name_without_extension = os.path.splitext(file_name)[0]\n",
    "    return file_name_without_extension\n",
    "\n",
    "# Define a function to process all *.docx files in a folder\n",
    "def process_docx_files(folder_path):\n",
    "    # Import keywords from the Excel file and turn them into a list\n",
    "    df = pd.read_excel('keywords.xlsx')\n",
    "    list_of_words = df['keywords'].tolist()\n",
    "    # Set up regex\n",
    "    patterns = [r'\\b' + word + r'\\b' for word in list_of_words]\n",
    "    re_highlight = re.compile('(' + '|'.join(p for p in patterns) + ')+', re.IGNORECASE)\n",
    "    docx_files = glob.glob(folder_path + '\\\\*.docx')\n",
    "    for file in docx_files:\n",
    "        doc = Document(file)\n",
    "        title = extract_file_name(file)  # Extract the file name without extension\n",
    "        modified_doc = Document()  # Create a new document to store modified paragraphs\n",
    "        modified_doc.add_heading(title, level=1)  # Add the title as Header 1 to the modified document\n",
    "        for para in doc.paragraphs:\n",
    "            text = para.text\n",
    "            if len(re_highlight.findall(text)) > 0:\n",
    "                matches = re_highlight.finditer(text)\n",
    "                p3 = 0\n",
    "                highlighted_para = modified_doc.add_paragraph()  # Add a new paragraph to the modified document\n",
    "                for match in matches:\n",
    "                    p1 = p3\n",
    "                    p2, p3 = match.span()\n",
    "                    highlighted_para.add_run(text[p1:p2])\n",
    "                    run = highlighted_para.add_run(text[p2:p3])\n",
    "                    run.font.highlight_color = WD_COLOR.YELLOW\n",
    "                    highlighted_para.add_run(text[p3:])\n",
    "        if modified_doc.paragraphs:  # Only save the modified document if it contains highlighted paragraphs\n",
    "            modified_doc.save(file)\n",
    "\n",
    "# Now convert them to .txt files\n",
    "\n",
    "def convert_to_txt(file):\n",
    "    w = wc.Dispatch('Word.Application')\n",
    "    doc = w.Documents.Open(file)\n",
    "    doc.SaveAs(file[:-5] + '.txt', 2)  # Save as a plain text file with .txt extension\n",
    "\n",
    "    doc.Close()  # Close the Word document\n",
    "    w.Quit()  # Close the Word application\n",
    "\n",
    "# Define a function to remove stopwords from a text file\n",
    "def clean_text(file_path):\n",
    "    stop_words = set(stopwords.words('french'))\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    cleaned_text = ' '.join(filtered_words)\n",
    "\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(cleaned_text)\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "# Provide the folder path where the algorithm will iterate over all *.docx files\n",
    "folder_path = r\".\\new_sample_docx\"\n",
    "process_docx_files(folder_path)\n",
    "\n",
    "directory = glob.glob(r\"C:\\Users\\garsonj\\Desktop\\NLP\\new_sample_docx\\*.docx\")\n",
    "\n",
    "for file in directory:\n",
    "    convert_to_txt(file)\n",
    "\n",
    "    # Move the converted .docx.txt file\n",
    "    if file.endswith(\".docx.txt\"):\n",
    "        file_path = os.path.join(r\"C:\\Users\\garsonj\\Desktop\\NLP\\new_sample_docx\", file)  # Update the file path\n",
    "        if os.path.isfile(file_path):\n",
    "            move_files(r\"C:\\Users\\garsonj\\Desktop\\NLP\\new_sample_docx\", r\"C:\\Users\\garsonj\\Desktop\\NLP\\sample_txt_not_cleaned\")\n",
    "            \n",
    "\n",
    "file_path = r\".\\sample_txt_not_cleaned\"\n",
    "\n",
    "for file in os.listdir(file_path):\n",
    "    if file.endswith(\".txt\"):\n",
    "        file_path = os.path.join(file_path, file)\n",
    "        if os.path.isfile(file_path):  # Verify the existence of the file\n",
    "            clean_text(file_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning 2 : stopwords + paragraph. This function works perfectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "from docx import Document\n",
    "from docx.enum.text import WD_COLOR\n",
    "from docxcompose.composer import Composer\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import shutil\n",
    "from win32com import client as wc\n",
    "\n",
    "# Define a function to move files from one folder to another\n",
    "def move_files(input_directory, output_directory):\n",
    "    for file in os.listdir(input_directory):\n",
    "        if file.endswith(\".docx.txt\"):\n",
    "            shutil.move(os.path.join(input_directory, file), output_directory)\n",
    "\n",
    "# Define a function to extract the file name without extension\n",
    "def extract_file_name(file):\n",
    "    file_name = os.path.basename(file)\n",
    "    file_name_without_extension = os.path.splitext(file_name)[0]\n",
    "    return file_name_without_extension\n",
    "\n",
    "# Define a function to process all *.docx files in a folder\n",
    "def process_docx_files(folder_path):\n",
    "    # Import keywords from the Excel file and turn them into a list\n",
    "    df = pd.read_excel('keywords.xlsx')\n",
    "    list_of_words = df['keywords'].tolist()\n",
    "    # Set up regex\n",
    "    patterns = [r'\\b' + word + r'\\b' for word in list_of_words]\n",
    "    re_highlight = re.compile('(' + '|'.join(p for p in patterns) + ')+', re.IGNORECASE)\n",
    "    docx_files = glob.glob(folder_path + '\\\\*.docx')\n",
    "    for file in docx_files:\n",
    "        doc = Document(file)\n",
    "        title = extract_file_name(file)  # Extract the file name without extension\n",
    "        modified_doc = Document()  # Create a new document to store modified paragraphs\n",
    "        modified_doc.add_heading(title, level=1)  # Add the title as Header 1 to the modified document\n",
    "        for para in doc.paragraphs:\n",
    "            text = para.text\n",
    "            if len(re_highlight.findall(text)) > 0:\n",
    "                matches = re_highlight.finditer(text)\n",
    "                p3 = 0\n",
    "                highlighted_para = modified_doc.add_paragraph()  # Add a new paragraph to the modified document\n",
    "                for match in matches:\n",
    "                    p1 = p3\n",
    "                    p2, p3 = match.span()\n",
    "                    highlighted_para.add_run(text[p1:p2])\n",
    "                    run = highlighted_para.add_run(text[p2:p3])\n",
    "                    run.font.highlight_color = WD_COLOR.YELLOW\n",
    "                    highlighted_para.add_run(text[p3:])\n",
    "        if modified_doc.paragraphs:  # Only save the modified document if it contains highlighted paragraphs\n",
    "            modified_doc.save(file)\n",
    "\n",
    "# Now convert them to .txt files\n",
    "def convert_to_txt(file):\n",
    "    w = wc.Dispatch('Word.Application')\n",
    "    doc = w.Documents.Open(file)\n",
    "    doc.SaveAs(file[:-5] + '.txt', 2)  # Save as a plain text file with .txt extension\n",
    "\n",
    "    doc.Close()  # Close the Word document\n",
    "    w.Quit()  # Close the Word application\n",
    "\n",
    "# Define a function to remove stopwords from a text file\n",
    "def clean_text(file_path):\n",
    "    stop_words = set(stopwords.words('french'))\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    cleaned_text = ' '.join(filtered_words)\n",
    "\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(cleaned_text)\n",
    "\n",
    "    return cleaned_text\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Provide the folder path where the algorithm will iterate over all *.docx files\n",
    "    folder_path = r\"C:\\Users\\garsonj\\Desktop\\NLP\\sample_docx_2\"\n",
    "    process_docx_files(folder_path)\n",
    "\n",
    "    directory = glob.glob(folder_path + r'\\*.docx')\n",
    "\n",
    "    for file in directory:\n",
    "        convert_to_txt(file)\n",
    "\n",
    "    # Move the converted .docx.txt file\n",
    "    move_files(folder_path, r\"C:\\Users\\garsonj\\Desktop\\NLP\\sample_cleaned_txt_2\")\n",
    "\n",
    "    file_path = r\"C:\\Users\\garsonj\\Desktop\\NLP\\sample_cleaned_txt_2\"\n",
    "\n",
    "    for file in os.listdir(file_path):\n",
    "        if file.endswith(\".txt\"):\n",
    "            file_path = os.path.join(file_path, file)\n",
    "            if os.path.isfile(file_path):  # Verify the existence of the file\n",
    "                clean_text(file_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning 3 : LangChain vectorization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version with Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.vectorstores import Chroma, Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import pinecone\n",
    "\n",
    "openai_api_key = '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'\n",
    "\n",
    "loader = DirectoryLoader(r'C:\\Users\\garsonj\\Desktop\\NLP\\sample_txt_not_cleaned', glob= '*.txt', loader_cls=TextLoader)\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=100)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "\n",
    "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY', 'ac6bd34c-1c15-4b7c-aef6-096ca1cf159c')\n",
    "PINECONE_API_ENV = os.environ.get('PINECONE_API_ENV', 'us-west1-gcp-free')\n",
    "\n",
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,  # find at app.pinecone.io\n",
    "    environment=PINECONE_API_ENV  # next to api key in console\n",
    ")\n",
    "index_name = \"legifrance\" # put in the name of your pinecone index here\n",
    "\n",
    "docsearch = Pinecone.from_texts([t.page_content for t in texts], embeddings, index_name=index_name)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version without Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\", \"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\")\n",
    "\n",
    "loader = DirectoryLoader('../NLP/sample_txt_not_cleaned', glob='**/*.txt', loader_cls=TextLoader)\n",
    "\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=100)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "\n",
    "docsearch = Chroma.from_documents(texts, embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from docx import Document\n",
    "import shutil\n",
    "\n",
    "openai.api_key = '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'\n",
    "\n",
    "\n",
    "def generate_summary(text):\n",
    "    try:\n",
    "        order = \"\"\"Tu es analyste GPT, un analyste expérimenté. Cela fait 10 ans que tu lis chaque accord de négociation annuelle obligatoire pour détecter les dynamiques salariales.\\\n",
    " Je vais te donner un texte et tu vas devoir résumer les points suivants et uniquement ceux-ci \\\n",
    "si ils sont disponibles (si non écrit 'information indisponible'): \\\n",
    "- Les augmentations générales. Attention beaucoup de synonyme comme \"augmentation brute\" ou \"du salaire de base\" \\En fonction des catégories socio-professionnelles/statut professionnel des salariés: ouvrier-employé ; Professions intermédiaires (techniciens, agents de maitrise, ou autres) ; cadres/ingénieurs.Le montant d'augmentation que tu dois prélever est en pourcent ou en euros. Il peut parfois être indiqué par rapport au SMIC ou à des grades/échelons allant de 1 à 9\\\n",
    "- Les augmentations individuelles de salaires.  Attention beaucoup de synonyme comme \"au mérite\", \\En fonction des catégories socio-professionnelles/statut professionnel des salariés: ouvrier-employé ; Professions intermédiaires (techniciens, agents de maitrise, ou autres) ; cadres/ingénieurs.Le montant d'augmentation que tu dois prélever est en pourcent ou en euros. Il peut parfois être indiqué par rapport au SMIC ou à des grades/échelons allant de 1 à 9\\\n",
    "- les primes de partage de la valeur ajoutée, ou PEPA, ou PPV ou prime Macron\n",
    " \\\n",
    "Donne une information par phrase et une phrase par bullet point\\\n",
    "Enfin, prend en compte la donnée suivante les augmentations générales quand elles sont différentes entre les salariés sont réparties de sorte à ce que les ouvriers-employés en aient plus que \\\n",
    "les intérmédiaries et cadres, et les intermédiaires plus que les cadres. Inversement pour les augmentations individuelles (aussi appelles au mérite), quand elles sont différentes entre les \\\n",
    "salariés, alors les cadres en reçoivent plus que les intérmediaires, qui en reçoivent plus que les employés-ouvrier. \\\n",
    "suis le modèle suivant # Augmentation générale # augmentation individuelle # Primes\\\n",
    "\n",
    "Voici le texte: \"\"\"\n",
    "\n",
    "        prompt = order + text\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        response = completion.choices[0].message.content\n",
    "        return response\n",
    "    except:\n",
    "        print(\"Error\")\n",
    "\n",
    "\n",
    "def save_summary_to_docx(summary, output_file):\n",
    "    file_name = os.path.basename(output_file)\n",
    "    document = Document()\n",
    "    document.add_paragraph(summary)\n",
    "    document.save(file_name)\n",
    "\n",
    "def move_files(source_folder, destination_folder):\n",
    "    for filename in os.listdir(source_folder):\n",
    "        if filename.endswith(\".docx\"):\n",
    "            file_path = os.path.join(source_folder, filename)\n",
    "            shutil.move(file_path, destination_folder)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder_path = r\".\\sample_cleaned_txt_2\"\n",
    "    output_folder = r\".\\summaryGPT\"\n",
    "\n",
    "    # Create the \"summaryGPT\" folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Iterate over the files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            # Read the text from the file\n",
    "            with open(file_path, 'r') as file:\n",
    "                text = file.read()\n",
    "\n",
    "            # Generate the summary\n",
    "            summary = generate_summary(text)\n",
    "\n",
    "            # Save the summary to a DOCX file\n",
    "            output_file = os.path.join(output_folder, filename.replace(\".txt\", \".docx\"))\n",
    "            save_summary_to_docx(summary, output_file)\n",
    "\n",
    "            # Move the file to the \"summaryGPT\" folder and overwrite if duplicate exists\n",
    "            move_files(r\"C:\\Users\\garsonj\\Desktop\\NLP\", r\".\\summaryGPT\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd Data Collection using LangChain and Kor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kor!\n",
    "from kor.extraction import create_extraction_chain\n",
    "from kor.nodes import Object, Text, Number\n",
    "\n",
    "# LangChain Models\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Standard Helpers\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "#from openai\n",
    "import openai\n",
    "\n",
    "openai_api_key = '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'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What model we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garsonj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\llms\\openai.py:179: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "C:\\Users\\garsonj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\llms\\openai.py:751: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(\n",
    "    model_name = \"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    "    max_tokens=1000, #token for completion\n",
    "    openai_api_key=openai_api_key\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our object extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'negociation': [{'augmentation_generale': '6%', 'augmentation_individuelle': 'information indisponible', 'prime': 'information indisponible'}, {'augmentation_generale': 'Input: Les salariés recevront une augmentation individuelle de 500 euros et une prime de 1000 euros.', 'augmentation_individuelle': '', 'prime': ''}, {'augmentation_generale': 'Output: augmentation_generale', 'augmentation_individuelle': 'augmentation_individuelle', 'prime': 'prime'}, {'augmentation_generale': 'information indisponible', 'augmentation_individuelle': '500 euros', 'prime': '1000 euros'}, {'augmentation_generale': 'Input: La prime de partage de la valeur ajoutée sera de 1500 euros par salarié.', 'augmentation_individuelle': '', 'prime': ''}, {'augmentation_generale': 'Output: augmentation_generale', 'augmentation_individuelle': 'augmentation_individuelle', 'prime': 'prime'}, {'augmentation_generale': 'information indisponible', 'augmentation_individuelle': 'information indisponible', 'prime': '1500 euros'}, {'augmentation_generale': 'Input: Le gouvernement a annoncé une prime Macron de 1000 euros pour les salariés touchant moins de 3 fois le SMIC.', 'augmentation_individuelle': '', 'prime': ''}, {'augmentation_generale': 'Output: augmentation_generale', 'augmentation_individuelle': 'augmentation_individuelle', 'prime': 'prime'}, {'augmentation_generale': 'information indisponible', 'augmentation_individuelle': 'information indisponible', 'prime': '1000 euros'}]}\n"
     ]
    }
   ],
   "source": [
    "nao_schema = Object(\n",
    "    id=\"negociation\",\n",
    "    description = \"information about wages increase in a company and bonuses. French documents\",\n",
    "\n",
    "    attributes=[\n",
    "        Number(\n",
    "            id=\"augmentation_generale\",\n",
    "            description=\"augmentation generale des salariés, en pourcentage ou en euros\",\n",
    "        ),\n",
    "        Number(\n",
    "            id=\"augmentation_individuelle\",\n",
    "            description=\"augmentation individuelle des salariés, en pourcentage ou en euros\",\n",
    "        ),\n",
    "        Number(\n",
    "            id=\"prime\",\n",
    "            description=\"prime de partage de la valeur ajoutée, ou PEPA, ou PPV ou prime Macron\",\n",
    "        ),\n",
    "    ],\n",
    "    examples=[\n",
    "        (\"Il est convenu une augmentation collective au 1er novembre 2022 de 6,25 %.\",\n",
    "         [{\"augmentation_generale\": \"6,25 %\", \"augmentation_individuelle\": \"information indisponible\", \"prime\": \"information indisponible\"}\n",
    "          ],\n",
    "            )\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'negociation': [{'augmentation_generale': '6%', 'augmentation_individuelle': 'information indisponible', 'prime': 'information indisponible'}, {'augmentation_generale': 'Input: Les salariés recevront une augmentation individuelle de 500 euros et une prime de 1000 euros.', 'augmentation_individuelle': '', 'prime': ''}, {'augmentation_generale': 'Output: augmentation_generale', 'augmentation_individuelle': 'augmentation_individuelle', 'prime': 'prime'}, {'augmentation_generale': 'information indisponible', 'augmentation_individuelle': '500 euros', 'prime': '1000 euros'}, {'augmentation_generale': 'Input: La prime de partage de la valeur ajoutée sera de 1500 euros par salarié.', 'augmentation_individuelle': '', 'prime': ''}, {'augmentation_generale': 'Output: augmentation_generale', 'augmentation_individuelle': 'augmentation_individuelle', 'prime': 'prime'}, {'augmentation_generale': 'information indisponible', 'augmentation_individuelle': 'information indisponible', 'prime': '1500 euros'}, {'augmentation_generale': 'Input: Le gouvernement a annoncé une prime Macron de 1000 euros pour les salariés touchant moins de 3 fois le SMIC.', 'augmentation_individuelle': '', 'prime': ''}, {'augmentation_generale': 'Output: augmentation_generale', 'augmentation_individuelle': 'augmentation_individuelle', 'prime': 'prime'}, {'augmentation_generale': 'information indisponible', 'augmentation_individuelle': 'information indisponible', 'prime': '1000 euros'}]}\n"
     ]
    }
   ],
   "source": [
    "text = \"Les salaires contractuels inférieurs à 2 400 Euros bruts seront majorés de 6%\"\n",
    "chain = create_extraction_chain(llm, nao_schema)\n",
    "output = chain.predict_and_parse(text=text)['data']\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_csp = Object(\n",
    "    id=\"augmentation_generale_csp\",\n",
    "    description=\"augmentation générale de salaire/salaire de base par catégorie socio-professionnelle, en pourcentage ou en euros\",\n",
    "    attributes=[\n",
    "        Number(id=\"ouvrier\", description=\"augmentation générale de salaire/salaire de base pour un employé/ouvrier, en pourcentage ou en euros\"),\n",
    "        Number(id=\"intermediaires\", description=\"augmentation générale de salaire/salaire de base pour une profession intermédiaire, technicien, agent de maitrise, en pourcentage ou en euros\"),\n",
    "        Number(id = \"cadres\", description=\"augmentation générale de salaire/salaire de base pour un cadre,ingénieur, en pourcentage ou en euros\")\n",
    "    ],\n",
    "    examples=[\n",
    "        (\n",
    "            \"\"\"5% au titre de l’Augmentation Générale, à l’ensemble des collaborateurs ouvriers, employés, techniciens \\\n",
    "            et agents de maitrise percevant en 2022 la PPCU (prime performance collective usine), en contrat CDD/CDI, \\ \n",
    "            justifiant d’une ancienneté supérieure ou égale à 6 mois au 31 décembre 2022. Les cadres bénéfiecerons d'une augmentation de 4%\"\"\",\n",
    "            [\n",
    "                {\"ouvrier\": \"5%\"},\n",
    "                {\"intermédiaires\": \"5%\"},\n",
    "                {\"cadres\": \"4%\"}\n",
    "            ],\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "augmentation = Object(\n",
    "    id=\"augmentation_generale\",\n",
    "    description=\"Information sur l'augmentation de la masse salariale\",\n",
    "    examples=[\n",
    "        (\n",
    "            \"\"\"A la suite de la demande de la Délégation syndicale CFDT, la Direction accepte de réserver une enveloppe de 5% de la Masse salariale. 5% au titre de l’Augmentation Générale,\\ \n",
    "            à l’ensemble des collaborateurs ouvriers, employés, techniciens \\\n",
    "            et agents de maitrise percevant en 2022 la PPCU (prime performance collective usine), en contrat CDD/CDI, justifiant d’une ancienneté supérieure ou égale à 6 mois au 31 décembre 2022\"\"\",\n",
    "            [\n",
    "                {\"augmentation générale\": \"1%\", \"parts\" : [\"employés\", \"agents de maitrise\"]}\n",
    "            ],\n",
    "        )\n",
    "    ],\n",
    "    attributes=[\n",
    "        Number(\n",
    "            id=\"augmentation_generale_tous_salaries\",\n",
    "            description=\"Augmentation générale accordée à tous les salariés indépendemment de leur catégorie socio-professionnelle, en pourcentage ou en euros\",\n",
    "        ),\n",
    "        augmentation_csp\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'augmentation_generale': {'augmentation_generale_tous_salaries': '6,25%'}}\n"
     ]
    }
   ],
   "source": [
    "# To do nested objects you need to specify encoder_or_encoder_class=\"json\"\n",
    "text = \"Il est convenu une augmentation collective au 1er novembre 2022 de 6,25 %.\"\n",
    "\n",
    "# Changed the encoder to json\n",
    "chain = create_extraction_chain(llm, augmentation, encoder_or_encoder_class=\"json\")\n",
    "output = chain.predict_and_parse(text=text)['data']\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your goal is to extract structured information from the user's input that matches the form described below. When extracting information please make sure it matches the type information exactly. Do not add any attributes that do not appear in the schema shown below.\n",
      "\n",
      "```TypeScript\n",
      "\n",
      "augmentation_generale: { // Information sur l'augmentation de la masse salariale\n",
      " augmentation_generale_tous_salaries: number // Augmentation générale accordée à tous les salariés indépendemment de leur catégorie socio-professionnelle, en pourcentage ou en euros\n",
      " augmentation_generale_csp: { // augmentation générale de salaire/salaire de base par catégorie socio-professionnelle, en pourcentage ou en euros\n",
      "  ouvrier: number // augmentation générale de salaire/salaire de base pour un employé/ouvrier, en pourcentage ou en euros\n",
      "  intermediaires: number // augmentation générale de salaire/salaire de base pour une profession intermédiaire, technicien, agent de maitrise, en pourcentage ou en euros\n",
      "  cadres: number // augmentation générale de salaire/salaire de base pour un cadre,ingénieur, en pourcentage ou en euros\n",
      " }\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "Please output the extracted information in JSON format. Do not output anything except for the extracted information. Do not add any clarifying information. Do not add any fields that are not in the schema. If the text contains attributes that do not appear in the schema, please ignore them. All output must be in JSON format and follow the schema specified above. Wrap the JSON in <json> tags.\n",
      "\n",
      "\n",
      "\n",
      "Input: A la suite de la demande de la Délégation syndicale CFDT, la Direction accepte de réserver une enveloppe de 5% de la Masse salariale. 5% au titre de l’Augmentation Générale,\\ \n",
      "            à l’ensemble des collaborateurs ouvriers, employés, techniciens             et agents de maitrise percevant en 2022 la PPCU (prime performance collective usine), en contrat CDD/CDI, justifiant d’une ancienneté supérieure ou égale à 6 mois au 31 décembre 2022\n",
      "Output: <json>{\"augmentation_generale\": [{\"augmentation générale\": \"1%\", \"parts\": [\"employés\", \"agents de maitrise\"]}]}</json>\n",
      "Input: 5% au titre de l’Augmentation Générale, à l’ensemble des collaborateurs ouvriers, employés, techniciens             et agents de maitrise percevant en 2022 la PPCU (prime performance collective usine), en contrat CDD/CDI, \\ \n",
      "            justifiant d’une ancienneté supérieure ou égale à 6 mois au 31 décembre 2022. Les cadres bénéfiecerons d'une augmentation de 4%\n",
      "Output: <json>{\"augmentation_generale\": {\"augmentation_generale_csp\": [{\"ouvrier\": \"5%\"}, {\"intermédiaires\": \"5%\"}, {\"cadres\": \"4%\"}]}}</json>\n",
      "Input: Il est convenu une augmentation collective au 1er novembre 2022 de 6,25 %.\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "prompt = chain.prompt.format_prompt(text=text).to_string()\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garsonj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\llms\\openai.py:179: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "C:\\Users\\garsonj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\llms\\openai.py:751: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'augmentation_generale': {'augmentation_generale_tous_salaries': '6,25%'}}\n",
      "{'augmentation_generale': {'augmentation_generale_tous_salaries': '3%', 'augmentation_generale_csp': [{'ouvrier': '3%'}, {'intermediaires': '3%'}, {'cadres': '1.5%'}]}}\n"
     ]
    }
   ],
   "source": [
    "# Kor!\n",
    "from kor.extraction import create_extraction_chain\n",
    "from kor.nodes import Object, Text, Number\n",
    "\n",
    "# LangChain Models\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Standard Helpers\n",
    "import pandas as pd\n",
    "import glob\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "#from openai\n",
    "import openai\n",
    "\n",
    "openai_api_key = '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'\n",
    "\n",
    "llm = OpenAI(\n",
    "    model_name = \"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    "    max_tokens=1000, #token for completion\n",
    "    openai_api_key=openai_api_key\n",
    ")\n",
    "\n",
    "augmentation_csp = Object(\n",
    "    id=\"augmentation_generale_csp\",\n",
    "    description=\"augmentation générale de salaire/salaire de base par catégorie socio-professionnelle, en pourcentage ou en euros\",\n",
    "    attributes=[\n",
    "        Number(id=\"ouvrier\", description=\"augmentation générale de salaire/salaire de base pour un employé/ouvrier, en pourcentage ou en euros\"),\n",
    "        Number(id=\"intermediaires\", description=\"augmentation générale de salaire/salaire de base pour une profession intermédiaire, technicien, agent de maitrise, en pourcentage ou en euros\"),\n",
    "        Number(id = \"cadres\", description=\"augmentation générale de salaire/salaire de base pour un cadre,ingénieur, en pourcentage ou en euros\")\n",
    "    ],\n",
    "    examples=[\n",
    "        (\n",
    "            \"\"\"5% au titre de l’Augmentation Générale, à l’ensemble des collaborateurs ouvriers, employés, techniciens \\\n",
    "            et agents de maitrise percevant en 2022 la PPCU (prime performance collective usine), en contrat CDD/CDI, \\ \n",
    "            justifiant d’une ancienneté supérieure ou égale à 6 mois au 31 décembre 2022. Les cadres bénéfiecerons d'une augmentation de 4%\"\"\",\n",
    "            [\n",
    "                {\"ouvrier\": \"5%\"},\n",
    "                {\"intermédiaires\": \"5%\"},\n",
    "                {\"cadres\": \"4%\"}\n",
    "            ],\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "augmentation = Object(\n",
    "    id=\"augmentation_generale\",\n",
    "    description=\"Information sur l'augmentation de la masse salariale\",\n",
    "    examples=[\n",
    "        (\n",
    "            \"\"\"A la suite de la demande de la Délégation syndicale CFDT, la Direction accepte de réserver une enveloppe de 5% de la Masse salariale. 5% au titre de l’Augmentation Générale,\\ \n",
    "            à l’ensemble des collaborateurs ouvriers, employés, techniciens \\\n",
    "            et agents de maitrise percevant en 2022 la PPCU (prime performance collective usine), en contrat CDD/CDI, justifiant d’une ancienneté supérieure ou égale à 6 mois au 31 décembre 2022\"\"\",\n",
    "            [\n",
    "                {\"augmentation générale\": \"1%\", \"parts\" : [\"employés\", \"agents de maitrise\"]}\n",
    "            ],\n",
    "        )\n",
    "    ],\n",
    "    attributes=[\n",
    "        Number(\n",
    "            id=\"augmentation_generale_tous_salaries\",\n",
    "            description=\"Augmentation générale accordée à tous les salariés indépendemment de leur catégorie socio-professionnelle, en pourcentage ou en euros\",\n",
    "        ),\n",
    "        augmentation_csp\n",
    "    ]\n",
    ")\n",
    "\n",
    "# To do nested objects you need to specify encoder_or_encoder_class=\"json\"\n",
    "directory = glob.glob(r\"C:\\Users\\garsonj\\Desktop\\NLP\\sample_txt_not_cleaned\\*.txt\")\n",
    "\n",
    "for file in directory:\n",
    "    with open(file, 'r') as f:\n",
    "        text = f.read()\n",
    "    # Changed the encoder to json\n",
    "    chain = create_extraction_chain(llm, augmentation, encoder_or_encoder_class=\"json\")\n",
    "    output = chain.predict_and_parse(text=text)['data']\n",
    "\n",
    "    print(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V.2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garsonj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\llms\\openai.py:179: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "C:\\Users\\garsonj\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\llms\\openai.py:751: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Kor!\n",
    "from kor.extraction import create_extraction_chain\n",
    "from kor.nodes import Object, Text, Number\n",
    "\n",
    "# LangChain Models\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Standard Helpers\n",
    "import pandas as pd\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "\n",
    "#from openai\n",
    "import openai\n",
    "\n",
    "openai_api_key = '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'\n",
    "\n",
    "llm = OpenAI(\n",
    "    model_name = \"gpt-3.5-turbo-16k\",\n",
    "    temperature=0,\n",
    "    max_tokens=1000, #token for completion\n",
    "    openai_api_key=openai_api_key\n",
    ")\n",
    "\n",
    "augmentation_gen_csp = Object(\n",
    "    id=\"augmentation_generale_csp\",\n",
    "    description=\"augmentation générale de salaire/salaire de base par catégorie socio-professionnelle, en pourcentage ou en euros\",\n",
    "    attributes=[\n",
    "        Number(id=\"ouvrier\", description=\"augmentation générale de salaire/salaire de base pour un employé/ouvrier, en pourcentage ou en euros\"),\n",
    "        Number(id=\"intermediaires\", description=\"augmentation générale de salaire/salaire de base pour une profession intermédiaire, technicien, agent de maitrise, en pourcentage ou en euros\"),\n",
    "        Number(id = \"cadres\", description=\"augmentation générale de salaire/salaire de base pour un cadre,ingénieur, en pourcentage ou en euros\")\n",
    "    ],\n",
    "    examples=[\n",
    "        (\n",
    "            \"\"\"5% au titre de l’Augmentation Générale, à l’ensemble des collaborateurs ouvriers, employés, techniciens \\\n",
    "            et agents de maitrise percevant en 2022 la PPCU (prime performance collective usine), en contrat CDD/CDI, \\ \n",
    "            justifiant d’une ancienneté supérieure ou égale à 6 mois au 31 décembre 2022. Les cadres bénéfiecerons d'une augmentation de 4%\"\"\",\n",
    "            [\n",
    "                {\"ouvrier\": \"5%\"},\n",
    "                {\"intermédiaires\": \"5%\"},\n",
    "                {\"cadres\": \"4%\"}\n",
    "            ],\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "augmentation_gen = Object(\n",
    "    id=\"augmentation_generale\",\n",
    "    description=\"Information sur l'augmentation de la masse salariale\",\n",
    "    examples=[\n",
    "        (\n",
    "            \"\"\"A la suite de la demande de la Délégation syndicale CFDT, la Direction accepte de réserver une enveloppe de 5% de la Masse salariale. 5% au titre de l’Augmentation Générale,\\ \n",
    "            à l’ensemble des collaborateurs ouvriers, employés, techniciens \\\n",
    "            et agents de maitrise percevant en 2022 la PPCU (prime performance collective usine), en contrat CDD/CDI, justifiant d’une ancienneté supérieure ou égale à 6 mois au 31 décembre 2022\"\"\",\n",
    "            [\n",
    "                {\"augmentation générale\": \"1%\", \"augmentation_gen_csp\" : [\"employés\", \"agents de maitrise\"]}\n",
    "            ],\n",
    "        )\n",
    "    ],\n",
    "    attributes=[\n",
    "        Number(\n",
    "            id=\"augmentation_generale_tous_salaries\",\n",
    "            description=\"Augmentation générale accordée à tous les salariés indépendemment de leur catégorie socio-professionnelle, en pourcentage ou en euros\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "augmentation_ind_csp = Object(\n",
    "    id=\"augmentation_ind_csp\",\n",
    "    description=\"augmentation individuelle de salaire ou mérite par catégorie socio-professionnelle, en pourcentage ou en euros\",\n",
    "    attributes=[\n",
    "        Number(id=\"ouvrier\", description=\"augmentation individuelle de salaire ou mérite pour un employé/ouvrier, en pourcentage ou en euros\"),\n",
    "        Number(id=\"intermediaires\", description=\"augmentation individuelle de salaire ou mérite pour une profession intermédiaire, technicien, agent de maitrise, en pourcentage ou en euros\"),\n",
    "        Number(id = \"cadres\", description=\"augmentation individuelle de salaire ou mérite pour un cadre,ingénieur, en pourcentage ou en euros\")\n",
    "    ],\n",
    "    examples=[\n",
    "        (\n",
    "            \"\"\"Mise en œuvre d’une révision salariale annuelle pérenne de 3% attribuée aux collaborateurs avec un salaire annuel brut de base inférieur ou égal à 50 000,00 euros,\\ \n",
    "            de  2% pour les collaborateurs avec un salaire annuel brut de base strictement supérieur à 50 000,00 euros et inférieur ou égal à 70 000,00 euros \\ \n",
    "            et de 1% pour les collaborateurs avec un salaire annuel brut de base strictement supérieur à 70 000,00 euros et inférieur ou égal à 90 000,00 euros.\"\"\",\n",
    "            [\n",
    "                {\"ouvrier\": \"3\"},\n",
    "                {\"intermédiaires\": \"2%\"},\n",
    "                {\"cadres\": \"1%\"}\n",
    "            ],\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "augmentation_ind = Object(\n",
    "    id=\"augmentation_ind\",\n",
    "    description=\"Information sur les augmentations individuelles ou au mérite\",\n",
    "    examples=[\n",
    "        (\n",
    "           \"\"\"Mise en œuvre d’une révision salariale annuelle pérenne de 3% attribuée aux collaborateurs avec un salaire annuel brut de base inférieur ou égal à 50 000,00 euros,\\ \n",
    "            de  2% pour les collaborateurs avec un salaire annuel brut de base strictement supérieur à 50 000,00 euros et inférieur ou égal à 70 000,00 euros \\ \n",
    "            et de 1% pour les collaborateurs avec un salaire annuel brut de base strictement supérieur à 70 000,00 euros et inférieur ou égal à 90 000,00 euros. La revalorisation globale au mérite est de 1%\"\"\",\n",
    "            [\n",
    "                {\"augmentation individuelle\": \"1%\", \"augmentation_ind_csp\" : [\"employés\", \"agents de maitrise\"]}\n",
    "            ],\n",
    "        )\n",
    "    ],\n",
    "    attributes=[\n",
    "        Number(\n",
    "            id=\"augmentation_generale_tous_salaries\",\n",
    "            description=\"Augmentation générale accordée à tous les salariés indépendemment de leur catégorie socio-professionnelle, en pourcentage ou en euros\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "node = Object(\n",
    "    id=\"root_node\",\n",
    "    attributes=[\n",
    "        augmentation_gen,\n",
    "        augmentation_ind,\n",
    "        augmentation_ind_csp,\n",
    "        augmentation_gen_csp\n",
    "    ]\n",
    ")\n",
    "\n",
    "directory = glob.glob(r\"C:\\Users\\garsonj\\Desktop\\NLP\\sample_txt_not_cleaned\\*.txt\")\n",
    "\n",
    "for file in directory:\n",
    "    with open(file, 'r') as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    # Retrieve file name\n",
    "    file_name = os.path.basename(file)\n",
    "    file_name_without_extension = os.path.splitext(file_name)[0]\n",
    "    \n",
    "    # Changed the encoder to json\n",
    "    chain = create_extraction_chain(llm, node, encoder_or_encoder_class=\"json\")\n",
    "    output = chain.predict_and_parse(text=text)['data']\n",
    "    \n",
    "    # Create JSON file with the same name as the original text file\n",
    "    json_file_name = file_name_without_extension + '.json'\n",
    "    with open(json_file_name, 'w') as json_file:\n",
    "        json.dump(output, json_file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kor!\n",
    "from kor.extraction import create_extraction_chain\n",
    "from kor.nodes import Object, Text, Number\n",
    "\n",
    "# LangChain Models\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Standard Helpers\n",
    "import pandas as pd\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "\n",
    "#from openai\n",
    "import openai\n",
    "\n",
    "openai_api_key = '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'\n",
    "\n",
    "llm = OpenAI(\n",
    "    model_name = \"gpt-3.5-turbo-16k\",\n",
    "    temperature=0,\n",
    "    max_tokens=230, #token for completion\n",
    "    openai_api_key=openai_api_key\n",
    ")\n",
    "\n",
    "augmentation_gen_ouv = Object(\n",
    "    id=\"augmentation_generale_ouv\",\n",
    "    description=\"augmentation générale de salaire/salaire de base pour les ouvriers et les employés, en pourcentage ou en euros\",\n",
    "    attributes=[\n",
    "        Number(id=\"ouvrier\", description=\"augmentation générale de salaire/salaire de base pour un employé/ouvrier, en pourcentage ou en euros\")\n",
    "    ],\n",
    "    examples=[\n",
    "        (\n",
    "            \"\"\"5% au titre de l’Augmentation Générale, à l’ensemble des collaborateurs ouvriers, employés, techniciens \\\n",
    "            et agents de maitrise percevant en 2022 la PPCU (prime performance collective usine), en contrat CDD/CDI, \\ \n",
    "            justifiant d’une ancienneté supérieure ou égale à 6 mois au 31 décembre 2022. Les cadres bénéfiecerons d'une augmentation de 4%\"\"\",\n",
    "            [\n",
    "                {\"ouvrier\": \"5%\"}\n",
    "            ],\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "augmentation_gen_int = Object(\n",
    "    id=\"augmentation_generale_int\",\n",
    "    description=\"augmentation générale de salaire/salaire de base pour les proféssions intermédiaires et agent de maîtrise, en pourcentage ou en euros\",\n",
    "    attributes=[\n",
    "        Number(id=\"intermediaires\", description=\"augmentation générale de salaire/salaire de base pour une profession intermédiaire, technicien, agent de maitrise, en pourcentage ou en euros\")\n",
    "    ],\n",
    "    examples=[\n",
    "        (\n",
    "            \"\"\"5% au titre de l’Augmentation Générale, à l’ensemble des collaborateurs ouvriers, employés, techniciens \\\n",
    "            et agents de maitrise percevant en 2022 la PPCU (prime performance collective usine), en contrat CDD/CDI, \\ \n",
    "            justifiant d’une ancienneté supérieure ou égale à 6 mois au 31 décembre 2022. Les cadres bénéfiecerons d'une augmentation de 4%\"\"\",\n",
    "            [\n",
    "                {\"ouvrier\": \"5%\"},\n",
    "                {\"intermédiaires\": \"5%\"},\n",
    "                {\"cadres\": \"4%\"}\n",
    "            ],\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "augmentation_gen_cad = Object(\n",
    "    id=\"augmentation_generale_csp\",\n",
    "    description=\"augmentation générale de salaire/salaire de base pour les cadres et ingénieurs, en pourcentage ou en euros\",\n",
    "    attributes=[\n",
    "        Number(id = \"cadres\", description=\"augmentation générale de salaire/salaire de base pour un cadre,ingénieur, en pourcentage ou en euros\")\n",
    "    ],\n",
    "    examples=[\n",
    "        (\n",
    "            \"\"\"5% au titre de l’Augmentation Générale, à l’ensemble des collaborateurs ouvriers, employés, techniciens \\\n",
    "            et agents de maitrise percevant en 2022 la PPCU (prime performance collective usine), en contrat CDD/CDI, \\ \n",
    "            justifiant d’une ancienneté supérieure ou égale à 6 mois au 31 décembre 2022. Les cadres bénéfiecerons d'une augmentation de 4%\"\"\",\n",
    "            [\n",
    "                {\"cadres\": \"4%\"}\n",
    "            ],\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "augmentation_gen = Object(\n",
    "    id=\"augmentation_generale\",\n",
    "    description=\"Information sur l'augmentation de la masse salariale\",\n",
    "    examples=[\n",
    "        (\n",
    "            \"\"\"A la suite de la demande de la Délégation syndicale CFDT, la Direction accepte de réserver une enveloppe de 5% de la Masse salariale. 5% au titre de l’Augmentation Générale,\\ \n",
    "            à l’ensemble des collaborateurs ouvriers, employés, techniciens \\\n",
    "            et agents de maitrise percevant en 2022 la PPCU (prime performance collective usine), en contrat CDD/CDI, justifiant d’une ancienneté supérieure ou égale à 6 mois au 31 décembre 2022\"\"\",\n",
    "            [\n",
    "                {\"augmentation générale\": \"1%\", \"augmentation_gen_csp\" : [\"employés\", \"agents de maitrise\"]}\n",
    "            ],\n",
    "        )\n",
    "    ],\n",
    "    attributes=[\n",
    "        Number(\n",
    "            id=\"augmentation_generale_tous_salaries\",\n",
    "            description=\"Augmentation générale accordée à tous les salariés indépendemment de leur catégorie socio-professionnelle, en pourcentage ou en euros\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "augmentation_ind_ouv = Object(\n",
    "    id=\"augmentation_ind_ouv\",\n",
    "    description=\"augmentation individuelle de salaire ou mérite pour les ouvriers et les employés, en pourcentage ou en euros\",\n",
    "    attributes=[\n",
    "        Number(id=\"ouvrier\", description=\"augmentation individuelle de salaire ou mérite pour un employé/ouvrier, en pourcentage ou en euros\")\n",
    "    ],\n",
    "    examples=[\n",
    "        (\n",
    "            \"\"\"Mise en œuvre d’une révision salariale annuelle pérenne de 3% attribuée aux collaborateurs avec un salaire annuel brut de base inférieur ou égal à 50 000,00 euros,\\ \n",
    "            de  2% pour les collaborateurs avec un salaire annuel brut de base strictement supérieur à 50 000,00 euros et inférieur ou égal à 70 000,00 euros \\ \n",
    "            et de 1% pour les collaborateurs avec un salaire annuel brut de base strictement supérieur à 70 000,00 euros et inférieur ou égal à 90 000,00 euros.\"\"\",\n",
    "            [\n",
    "                {\"ouvrier\": \"3\"}\n",
    "            ],\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "augmentation_ind_int = Object(\n",
    "    id=\"augmentation_ind_int\",\n",
    "    description=\"augmentation individuelle de salaire ou mérite pour les professions intermédiaires, techniniciens, en pourcentage ou en euros\",\n",
    "    attributes=[\n",
    "        \n",
    "        Number(id=\"intermediaires\", description=\"augmentation individuelle de salaire ou mérite pour une profession intermédiaire, technicien, agent de maitrise, en pourcentage ou en euros\")\n",
    "    ],\n",
    "    examples=[\n",
    "        (\n",
    "            \"\"\"Mise en œuvre d’une révision salariale annuelle pérenne de 3% attribuée aux collaborateurs avec un salaire annuel brut de base inférieur ou égal à 50 000,00 euros,\\ \n",
    "            de  2% pour les collaborateurs avec un salaire annuel brut de base strictement supérieur à 50 000,00 euros et inférieur ou égal à 70 000,00 euros \\ \n",
    "            et de 1% pour les collaborateurs avec un salaire annuel brut de base strictement supérieur à 70 000,00 euros et inférieur ou égal à 90 000,00 euros.\"\"\",\n",
    "            [\n",
    "                {\"intermédiaires\": \"2%\"},\n",
    "            ],\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "augmentation_ind_cad = Object(\n",
    "    id=\"augmentation_ind_cad\",\n",
    "    description=\"augmentation individuelle de salaire ou mérite pour les cadres et ingénieurs, en pourcentage ou en euros\",\n",
    "    attributes=[\n",
    "        Number(id = \"cadres\", description=\"augmentation individuelle de salaire ou mérite pour un cadre,ingénieur, en pourcentage ou en euros\")\n",
    "    ],\n",
    "    examples=[\n",
    "        (\n",
    "            \"\"\"Mise en œuvre d’une révision salariale annuelle pérenne de 3% attribuée aux collaborateurs avec un salaire annuel brut de base inférieur ou égal à 50 000,00 euros,\\ \n",
    "            de  2% pour les collaborateurs avec un salaire annuel brut de base strictement supérieur à 50 000,00 euros et inférieur ou égal à 70 000,00 euros \\ \n",
    "            et de 1% pour les collaborateurs avec un salaire annuel brut de base strictement supérieur à 70 000,00 euros et inférieur ou égal à 90 000,00 euros.\"\"\",\n",
    "            [\n",
    "                {\"cadres\": \"1%\"}\n",
    "            ],\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "augmentation_ind = Object(\n",
    "    id=\"augmentation_ind\",\n",
    "    description=\"Information sur les augmentations individuelles ou au mérite\",\n",
    "    examples=[\n",
    "        (\n",
    "           \"\"\"Mise en œuvre d’une révision salariale annuelle pérenne de 3% attribuée aux collaborateurs avec un salaire annuel brut de base inférieur ou égal à 50 000,00 euros,\\ \n",
    "            de  2% pour les collaborateurs avec un salaire annuel brut de base strictement supérieur à 50 000,00 euros et inférieur ou égal à 70 000,00 euros \\ \n",
    "            et de 1% pour les collaborateurs avec un salaire annuel brut de base strictement supérieur à 70 000,00 euros et inférieur ou égal à 90 000,00 euros. La revalorisation globale au mérite est de 1%\"\"\",\n",
    "            [\n",
    "                {\"augmentation individuelle\": \"1%\", \"augmentation_ind_csp\" : [\"employés\", \"agents de maitrise\"]}\n",
    "            ],\n",
    "        )\n",
    "    ],\n",
    "    attributes=[\n",
    "        Number(\n",
    "            id=\"augmentation_generale_tous_salaries\",\n",
    "            description=\"Augmentation générale accordée à tous les salariés indépendemment de leur catégorie socio-professionnelle, en pourcentage ou en euros\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "node = Object(\n",
    "    id=\"root_node\",\n",
    "    attributes=[\n",
    "        augmentation_gen,\n",
    "        augmentation_gen_ouv,\n",
    "        augmentation_gen_int,\n",
    "        augmentation_gen_cad,\n",
    "        augmentation_ind,\n",
    "        augmentation_ind_ouv,\n",
    "        augmentation_ind_int,\n",
    "        augmentation_ind_cad\n",
    "    ]\n",
    ")\n",
    "\n",
    "directory = glob.glob(r\"C:\\Users\\garsonj\\Desktop\\NLP\\sample_txt_not_cleaned\\*.txt\")\n",
    "\n",
    "for file in directory:\n",
    "    with open(file, 'r') as f:\n",
    "        text = f.read()\n",
    "             \n",
    "        # Retrieve file name\n",
    "        file_name = os.path.basename(file)\n",
    "        file_name_without_extension = os.path.splitext(file_name)[0]\n",
    "            \n",
    "        # Changed the encoder to json\n",
    "        chain = create_extraction_chain(llm, node, encoder_or_encoder_class=\"json\")\n",
    "        output = chain.predict_and_parse(text=text)['data']\n",
    "            \n",
    "        # Create JSON file with the same name as the original text file\n",
    "        json_file_name = file_name_without_extension + '.json'\n",
    "        with open(json_file_name, 'w') as json_file:\n",
    "            json.dump(output, json_file)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n\u001b[0;32m     22\u001b[0m \u001b[39m# Usage:\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m df \u001b[39m=\u001b[39m generate_dataframe(json_data)\n\u001b[0;32m     24\u001b[0m df\u001b[39m.\u001b[39mhead()\n",
      "Cell \u001b[1;32mIn[71], line 12\u001b[0m, in \u001b[0;36mgenerate_dataframe\u001b[1;34m(json_data)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m record \u001b[39min\u001b[39;00m json_data:\n\u001b[0;32m     11\u001b[0m   \u001b[39mfor\u001b[39;00m record \u001b[39min\u001b[39;00m json_data:\n\u001b[1;32m---> 12\u001b[0m     nao_list \u001b[39m=\u001b[39m record\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39m\u001b[39mroot_node\u001b[39m\u001b[39m'\u001b[39m, {})\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39maugmentation_gen_ouv\u001b[39m\u001b[39m'\u001b[39m, [])\n\u001b[0;32m     13\u001b[0m     \u001b[39mfor\u001b[39;00m num \u001b[39min\u001b[39;00m nao_list:\n\u001b[0;32m     14\u001b[0m         name \u001b[39m=\u001b[39m num\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39maugmentation_gen_ouv\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'get'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with open('T03822012103-80041849300022.docx.json', 'r') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "\n",
    "def generate_dataframe(json_data):\n",
    "    # Prepare an empty list to store all restaurant data\n",
    "    data = []\n",
    "\n",
    "    for record in json_data:\n",
    "      for record in json_data:\n",
    "        nao_list = record.get('root_node', {}).get('augmentation_gen_ouv', [])\n",
    "        for num in nao_list:\n",
    "            name = num.get('augmentation_gen_ouv', '')\n",
    "            print(f'Restaurant Name: {name}')\n",
    "            \n",
    "    # Convert the list into a DataFrame\n",
    "    df = pd.DataFrame(data, columns=['Name', 'Location', 'Style', 'Top Dish'])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Usage:\n",
    "df = generate_dataframe(json_data)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "directory = r\"C:\\Users\\garsonj\\Desktop\\NLP\"\n",
    "# Assuming 'directory' is the path to the folder containing JSON files\n",
    "\n",
    "dfs = []  # List to store DataFrames from each JSON file\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    if file.endswith('.json'):  # Check if the file is a JSON file\n",
    "        file_path = os.path.join(directory, file)\n",
    "        \n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Convert the JSON data to a DataFrame and append it to the list\n",
    "        df = pd.DataFrame([data])\n",
    "        dfs.append(df)\n",
    "\n",
    "# Combine DataFrames column-wise\n",
    "combined_df = pd.concat(dfs, axis=1).transpose()\n",
    "# Print the combined DataFrame\n",
    "combined_df.to_csv('combined_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
